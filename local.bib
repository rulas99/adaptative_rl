@inproceedings{norman2024firstexploreexploitmetalearningsolve,
 author = {Norman, Ben and Clune, Jeff},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Globerson and L. Mackey and D. Belgrave and A. Fan and U. Paquet and J. Tomczak and C. Zhang},
 pages = {27490--27528},
 publisher = {Curran Associates, Inc.},
 title = {First-Explore, then Exploit: Meta-Learning to Solve Hard Exploration-Exploitation Trade-Offs},
 url = {https://proceedings.neurips.cc/paper_files/paper/2024/file/30754e5f4cd69d64b5527cdd87d3cf62-Paper-Conference.pdf},
 volume = {37},
 year = {2024}
}

@book{sutton18,
	author = {{Richard S. Sutton and Andrew G. Barto}},
	isbn = {9780262039246},
	pages = {550},
	publisher = {MIT Press},
	title = {{Reinforcement Learning, An Introduction}},
	edition = {Second Edition},
	year = {2018}}


@inproceedings{abel2023definitioncontinualreinforcementlearning,
title={A Definition of Continual Reinforcement Learning},
author={David Abel and Andre Barreto and Benjamin Van Roy and Doina Precup and Hado van Hasselt and Satinder Singh},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=ZZS9WEWYbD}
}

@article{HENRICHS2022106940,
title = {A literature review on optimization techniques for adaptation planning in adaptive systems: State of the art and research directions},
journal = {Information and Software Technology},
volume = {149},
pages = {106940},
year = {2022},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2022.106940},
url = {https://www.sciencedirect.com/science/article/pii/S0950584922000891},
author = {Elia Henrichs and Veronika Lesch and Martin Straesser and Samuel Kounev and Christian Krupitzer},
keywords = {Self-adaptive systems, Adaptation planning, Optimization, Survey},
}

@article{khetarpal2022continualreinforcementlearningreview,
  title={Towards Continual Reinforcement Learning: A Review and Perspectives},
  author={Khimya Khetarpal and Matthew Riemer and Irina Rish and Doina Precup},
  journal={J. Artif. Intell. Res.},
  year={2020},
  volume={75},
  pages={1401-1476},
  url={https://api.semanticscholar.org/CorpusID:229679944}
}

@misc{chen2022transferredqlearning,
      title={Transferred Q-learning}, 
      author={Elynn Y. Chen and Michael I. Jordan and Sai Li},
      year={2022},
      eprint={2202.04709},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2202.04709}, 
}

@misc{beck2024surveymetareinforcementlearning,
      title={A Survey of Meta-Reinforcement Learning}, 
      author={Jacob Beck and Risto Vuorio and Evan Zheran Liu and Zheng Xiong and Luisa Zintgraf and Chelsea Finn and Shimon Whiteson},
      year={2024},
      eprint={2301.08028},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2301.08028}, 
}

@article{zhuang20,
author = {Zhuang, Fuzhen and Qi, Zhiyuan and Duan, Keyu and Xi, Dongbo and Zhu, Yongchun and Zhu, Hengshu and Xiong, Hui and He, Qing},
year = {2020},
month = {07},
pages = {1-34},
title = {A Comprehensive Survey on Transfer Learning},
volume = {PP},
journal = {Proceedings of the IEEE},
doi = {10.1109/JPROC.2020.3004555}
}

@misc{kingma2017adammethodstochasticoptimization,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1412.6980}, 
}

@article{meta-rl-traffic,
author = {Kim, Gyeongjun and Kang, Jiwon and Sohn, Keemin},
year = {2022},
month = {09},
pages = {},
title = {A meta–reinforcement learning algorithm for traffic signal control to automatically switch different reward functions according to the saturation level of traffic flows},
volume = {38},
journal = {Computer-Aided Civil and Infrastructure Engineering},
doi = {10.1111/mice.12924}
}

@article{dynamicrlalpha,
author = {Donancio, Henrique and Barrier, Antoine and South, Leah and Forbes, Florence},
year = {2024},
month = {10},
pages = {},
title = {Dynamic Learning Rate for Deep Reinforcement Learning: A Bandit Approach},
doi = {10.48550/arXiv.2410.12598}
}


@article{MORENOMALO2024124178,
title = {Improving traffic light systems using Deep Q-networks},
journal = {Expert Systems with Applications},
volume = {252},
pages = {124178},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124178},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424010443},
author = {Juan Moreno-Malo and Juan-Luis Posadas-Yagüe and Juan Carlos Cano and Carlos T. Calafate and J. Alberto Conejero and Jose-Luis Poza-Lujan},
keywords = {Deep-Q networks, Urban traffic optimization, Neural network, SUMO},
}

@inproceedings{tokic2010,
author = {Tokic, Michel},
year = {2010},
month = {09},
pages = {203-210},
title = {Adaptive ε-Greedy Exploration in Reinforcement Learning Based on Value Differences},
isbn = {978-3-642-16110-0},
doi = {10.1007/978-3-642-16111-7_23}
}

@article{mignon2017adaptive,
author = {Mignon, Alexandre and A. Rocha, Ricardo Luis},
year = {2017},
month = {12},
pages = {1146-1151},
title = {An Adaptive Implementation of ε-Greedy in Reinforcement Learning},
volume = {109},
journal = {Procedia Computer Science},
doi = {10.1016/j.procs.2017.05.431}
}

@inproceedings{inproceedings,
author = {Wassermann, Sarah and Cuvelier, Thibaut and Mulinka, Pavol and Casas, Pedro},
year = {2019},
month = {10},
pages = {},
title = {ADAM & RAL: Adaptive Memory Learning and Reinforcement Active Learning for Network Monitoring},
doi = {10.23919/CNSM46954.2019.9012675}
}

@article{networkdynamicrl,
author = {Wassermann, Sarah and Cuvelier, Thibaut and Mulinka, Pavol and Casas, Pedro},
year = {2020},
month = {11},
pages = {1-1},
title = {Adaptive and Reinforcement Learning Approaches for Online Network Monitoring and Analysis},
volume = {PP},
journal = {IEEE Transactions on Network and Service Management},
doi = {10.1109/TNSM.2020.3037486}
}

@article{iotdynamicrl,
author = {Kumar, Anit and Singh, Dhanpratap},
year = {2024},
month = {11},
pages = {},
title = {Adaptive epsilon greedy reinforcement learning method in securing IoT devices in edge computing},
volume = {4},
journal = {Discover Internet of Things},
doi = {10.1007/s43926-024-00080-7}
}

@inproceedings{10.1609/aaai.v37i6.25899,
author = {Ding, Wei and Jiang, Siyang and Chen, Hsi-Wen and Chen, Ming-Syan},
title = {Incremental reinforcement learning with dual-adaptive ε-greedy exploration},
year = {2023},
isbn = {978-1-57735-880-0},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v37i6.25899},
doi = {10.1609/aaai.v37i6.25899},
booktitle = {Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and Thirteenth Symposium on Educational Advances in Artificial Intelligence},
articleno = {830},
numpages = {9},
series = {AAAI'23/IAAI'23/EAAI'23}
}

@Article{Swapno2024,
author={Swapno, S. M. Masfequier Rahman
and Nobel, SM Nuruzzaman
and Meena, Preeti
and Meena, V. P.
and Azar, Ahmad Taher
and Haider, Zeeshan
and Tounsi, Mohamed},
title={A reinforcement learning approach for reducing traffic congestion using deep Q learning},
journal={Scientific Reports},
year={2024},
month={Dec},
day={12},
volume={14},
number={1},
pages={30452},
issn={2045-2322},
doi={10.1038/s41598-024-75638-0},
url={https://doi.org/10.1038/s41598-024-75638-0}
}

@inproceedings{zintgraf21,
  title={Exploration in approximate hyper-state space for meta reinforcement learning},
  author={Zintgraf, Luisa M and Feng, Leo and Lu, Cong and Igl, Maximilian and Hartikainen, Kristian and Hofmann, Katja and Whiteson, Shimon},
  booktitle={International Conference on Machine Learning},
  pages={12991--13001},
  year={2021},
  organization={PMLR}
}

@article{WONG2022106934,
title = {Self-adaptive systems: A systematic literature review across categories and domains},
journal = {Information and Software Technology},
volume = {148},
pages = {106934},
year = {2022},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2022.106934},
url = {https://www.sciencedirect.com/science/article/pii/S0950584922000854},
author = {Terence Wong and Markus Wagner and Christoph Treude},
keywords = {Self-adaptive systems, Literature review}
}

@misc{araujo2020controladaptiveqlearning,
      title={Control with adaptive Q-learning}, 
      author={João Pedro Araújo and Mário A. T. Figueiredo and Miguel Ayala Botto},
      year={2020},
      eprint={2011.02141},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2011.02141}, 
}

@inproceedings{Bagus2022,
   title={A Study of Continual Learning Methods for Q-Learning},
   url={http://dx.doi.org/10.1109/IJCNN55064.2022.9892384},
   DOI={10.1109/ijcnn55064.2022.9892384},
   booktitle={International Joint Conference on Neural Networks (IJCNN)},
   publisher={IEEE},
   author={Bagus, Benedikt and Gepperth, Alexander},
   year={2022},
   month={07}, 
   pages={1–9} 
}

@inproceedings{florensa18,
  title={Automatic goal generation for reinforcement learning agents},
  author={Florensa, Carlos and Held, David and Geng, Xinyang and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={1515--1528},
  year={2018},
  organization={PMLR}
}

@inproceedings{eiben20evolving,
  title={Evolving robot software and hardware},
  author={Eiben, AE},
  booktitle={Proceedings of the IEEE/ACM International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
  series={SEAMS'20},
  pages={1--4},
  year={2020}
}

@article{miras20environmental,
  title={Environmental influences on evolvable robots},
  author={Miras, Karine and Ferrante, Eliseo and Eiben, Agoston E},
  journal={PloS one},
  volume={15},
  number={5},
  pages={e0233848},
  year={2020},
  publisher={Public Library of Science San Francisco, CA USA}
}

@article{schranz20swarm,
  title={Swarm robotic behaviors and current applications},
  author={Schranz, Melanie and Umlauft, Martina and Sende, Micha and Elmenreich, Wilfried},
  journal={Frontiers in Robotics and AI},
  volume={7},
  pages={36},
  year={2020},
  publisher={Frontiers Media SA}
}

@misc{gymlib,
      title={Gymnasium: A Standard Interface for Reinforcement Learning Environments}, 
      author={Mark Towers and Ariel Kwiatkowski and Jordan Terry and John U. Balis and Gianluca De Cola and Tristan Deleu and Manuel Goulão and Andreas Kallinteris and Markus Krimmel and Arjun KG and Rodrigo Perez-Vicente and Andrea Pierré and Sander Schulhoff and Jun Jet Tai and Hannah Tan and Omar G. Younis},
      year={2024},
      eprint={2407.17032},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2407.17032}, 
}

@article{changingpointdetection,
author = {Hartland, Cédric and Baskiotis, Nicolas and Gelly, Sylvain and Sebag, Michèle and Teytaud, Olivier},
year = {2011},
month = {04},
pages = {},
title = {Change Point Detection and Meta-Bandits for Online Learning in Dynamic Environments}
}


@inproceedings{ConstructivistRL,
author = {Guériau, Maxime and Cardozo, Nicolás and Dusparic, Ivana},
year = {2019},
month = {06},
pages = {},
title = {Constructivist Approach to State Space Adaptation in Reinforcement Learning},
doi = {10.1109/SASO.2019.00016}
}

@article{nonstationaryqlearning,
author = {Abdallah, Sherief and Kaisers, Michael},
year = {2016},
month = {04},
pages = {},
title = {Addressing environment non-stationarity by repeating Q-learning updates},
volume = {17}
}



@InProceedings{pmlr-v139-mao21b,
  title = 	 {Near-Optimal Model-Free Reinforcement Learning in Non-Stationary Episodic MDPs},
  author =       {Mao, Weichao and Zhang, Kaiqing and Zhu, Ruihao and Simchi-Levi, David and Basar, Tamer},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {7447--7458},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/mao21b/mao21b.pdf},
  url = 	 {https://proceedings.mlr.press/v139/mao21b.html}
  }


@article{Padakandla_2020,
   title={Reinforcement learning algorithm for non-stationary environments},
   volume={50},
   ISSN={1573-7497},
   url={http://dx.doi.org/10.1007/s10489-020-01758-5},
   DOI={10.1007/s10489-020-01758-5},
   number={11},
   journal={Applied Intelligence},
   publisher={Springer Science and Business Media LLC},
   author={Padakandla, Sindhu and K. J., Prabuchandran and Bhatnagar, Shalabh},
   year={2020},
   month=jun, pages={3590–3606} }

@article{Padakandla_2021,
   title={A Survey of Reinforcement Learning Algorithms for Dynamically Varying Environments},
   volume={54},
   ISSN={1557-7341},
   url={http://dx.doi.org/10.1145/3459991},
   DOI={10.1145/3459991},
   number={6},
   journal={ACM Computing Surveys},
   publisher={Association for Computing Machinery (ACM)},
   author={Padakandla, Sindhu},
   year={2021},
   month=jul, pages={1–25} }




