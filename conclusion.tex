% $Id: conclusion.tex 
% !TEX root = main.tex

%%
\section{Conclusion and Future Work}
\label{sec:conclusion}

This paper introduced \adaptiverl, a self-adaptive framework for tabular Q-learning agents operating in non-stationary environments. We specifically addressed the challenge of agents adapting to simultaneous changes in their goals (reward functions) and their available capabilities (action-space expansions). Our approach integrates concept drift detection using the Page-Hinkley test with dynamic adjustments to the exploration ($\varepsilon$) and learning ($\alpha$) rates. Experimental results in both a Gridworld benchmark and a traffic control simulation demonstrate that this coordinated strategy enables agents to adapt more effectively than a standard Q-learning baseline, achieving a performance increase of up to $1.9\times$ in learning efficiency while successfully mitigating catastrophic forgetting.

The primary contribution of this work is not a single algorithmic breakthrough, but the synthesis of these established techniques into a unified, lightweight, and model-free framework. By preserving and continuously adapting a single Q-table, \adaptiverl provides an effective mechanism for continual learning, enabling knowledge reuse even when faced with contradictory environmental changes, a key challenge highlighted by~\citet{Bagus2022}. Our approach stands as a practical method for developing self-adaptive systems that require real-time learning in dynamic environments with limited computational resources.

This work represents an initial validation, and several avenues for future work are evident. The limitations observed in our experiments, such as the failure of the PH-test to detect certain drifts and the need for empirical tuning of hyperparameters, point to clear directions for improvement. Future work should therefore focus on:
\begin{enumerate}
    \item Generalization and Scalability: Extending the core principles of \adaptiverl from tabular methods to deep \ac{RL} architectures to handle high-dimensional state spaces. This would also involve investigating the use of memory-based plasticity to enhance knowledge transfer across tasks.
    \item Robustness and Empirical Analysis: Conducting a rigorous sensitivity analysis of the introduced hyperparameters, particularly the TD-error sensitivity ($k$), to better understand their impact. Furthermore, we plan to explore more robust drift detection methods and extend the evaluation to include scenarios with action removal, not just expansion.
    \item Advanced Application Domains: Applying the framework to more complex distributed multi-agent systems. Finally, we plan to deploy \adaptiverl on resource-constrained edge devices for real-world applications in \ac{IOT} and robotics.
\end{enumerate}

\endinput